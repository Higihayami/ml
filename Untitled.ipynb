{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e346e70-e3ba-48f7-a32a-d0081dee9635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/datasets/atulanandjha/imdb-50k-movie-reviews-test-your-bert?select=test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e0e32098-b5a9-4849-8c29-05dcd77c9334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\fatik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\fatik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: nltk in c:\\users\\fatik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\fatik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\fatik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\fatik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: click in c:\\users\\fatik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\fatik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\fatik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\fatik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\fatik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\fatik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\users\\fatik\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\fatik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\fatik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\fatik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install pandas numpy nltk\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f806ae65-a58e-4ab9-9041-c39f45105bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.4.1.post1-cp39-cp39-win_amd64.whl (10.6 MB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\fatik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0\n",
      "  Downloading scipy-1.12.0-cp39-cp39-win_amd64.whl (46.2 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\fatik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Installing collected packages: scipy, threadpoolctl, scikit-learn\n",
      "Successfully installed scikit-learn-1.4.1.post1 scipy-1.12.0 threadpoolctl-3.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\users\\fatik\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b99f05ea-45d9-4a69-b430-41dd5c641b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text sentiment\n",
      "0  daughter liked aghast , character movie smoke ...       neg\n",
      "1  ... word . word describe . try sake brave peop...       neg\n",
      "2  film basically poor take old urban legend baby...       neg\n",
      "3  terrible movie , 'm even sure 's terrible . 's...       neg\n",
      "4  first movie piece reality well realized artist...       pos\n"
     ]
    }
   ],
   "source": [
    "# Загрузка датасета\n",
    "df = pd.read_csv('test.csv')  \n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    # Токенизация\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # Удаление стоп-слов\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Лемматизация\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    # Объединение токенов обратно в текст\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text\n",
    "\n",
    "df['text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "36b1deb8-b996-4aa2-874f-8e83697300bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text sentiment  00  000  \\\n",
      "0  daughter liked aghast , character movie smoke ...       neg   0    0   \n",
      "1  ... word . word describe . try sake brave peop...       neg   0    0   \n",
      "2  film basically poor take old urban legend baby...       neg   0    0   \n",
      "3  terrible movie , 'm even sure 's terrible . 's...       neg   0    0   \n",
      "4  first movie piece reality well realized artist...       pos   0    0   \n",
      "\n",
      "   00000000000  00000001  000dm  001  0069  007  ...  überwoman  ünel  \\\n",
      "0            0         0      0    0     0    0  ...          0     0   \n",
      "1            0         0      0    0     0    0  ...          0     0   \n",
      "2            0         0      0    0     0    0  ...          0     0   \n",
      "3            0         0      0    0     0    0  ...          0     0   \n",
      "4            0         0      0    0     0    0  ...          0     0   \n",
      "\n",
      "   ünfaithful  üzümcü  ýs  þorleifsson  þór  żmijewski  יגאל  כרמון  \n",
      "0           0       0   0            0    0          0     0      0  \n",
      "1           0       0   0            0    0          0     0      0  \n",
      "2           0       0   0            0    0          0     0      0  \n",
      "3           0       0   0            0    0          0     0      0  \n",
      "4           0       0   0            0    0          0     0      0  \n",
      "\n",
      "[5 rows x 68255 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# Создание экземпляра CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "\n",
    "bow_df = pd.DataFrame.sparse.from_spmatrix(X, columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "df_bow = pd.concat([df, bow_df], axis=1)\n",
    "\n",
    "print(df_bow.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "742f667b-f382-4ecb-a06d-315576c7bcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1746)\t0.20722062778845346\n",
      "  (0, 31118)\t0.15712591618796062\n",
      "  (0, 55705)\t0.18612640927110397\n",
      "  (0, 5314)\t0.258299513651735\n",
      "  (0, 59526)\t0.0831446277683261\n",
      "  (0, 22523)\t0.1408573656572451\n",
      "  (0, 56860)\t0.2506513811693412\n",
      "  (0, 61122)\t0.24189648946665898\n",
      "  (0, 6669)\t0.09687413061654844\n",
      "  (0, 31135)\t0.21157554771084985\n",
      "  (0, 67008)\t0.1261630624856939\n",
      "  (0, 13108)\t0.265638683841361\n",
      "  (0, 11033)\t0.22073894184142087\n",
      "  (0, 34911)\t0.1982771316123151\n",
      "  (0, 66654)\t0.20270383235435555\n",
      "  (0, 8595)\t0.16880742601704532\n",
      "  (0, 35459)\t0.0536267180002675\n",
      "  (0, 1552)\t0.07942517578319769\n",
      "  (0, 45907)\t0.2361373776863723\n",
      "  (0, 47408)\t0.16892248295729584\n",
      "  (0, 53419)\t0.06358858788954391\n",
      "  (0, 20165)\t0.09589612390715939\n",
      "  (0, 4858)\t0.11731638952383695\n",
      "  (0, 55697)\t0.37516159963322737\n",
      "  (0, 40332)\t0.13119422710139952\n",
      "  :\t:\n",
      "  (4, 5927)\t0.09625120188321254\n",
      "  (4, 2824)\t0.07174939509243015\n",
      "  (4, 12368)\t0.11354261300520527\n",
      "  (4, 4079)\t0.1502408824289187\n",
      "  (4, 49087)\t0.10787816159981137\n",
      "  (4, 66110)\t0.08816500952379949\n",
      "  (4, 49083)\t0.0870746405118177\n",
      "  (4, 25765)\t0.03956374622009596\n",
      "  (4, 60922)\t0.07651158664194273\n",
      "  (4, 56175)\t0.05618456654510985\n",
      "  (4, 22729)\t0.0478895083288865\n",
      "  (4, 22612)\t0.056785035103182675\n",
      "  (4, 25068)\t0.0425274461167564\n",
      "  (4, 41319)\t0.10619837601628175\n",
      "  (4, 49093)\t0.0442701817160292\n",
      "  (4, 22079)\t0.0973703446548808\n",
      "  (4, 33541)\t0.06656294977391562\n",
      "  (4, 47347)\t0.0666535334216833\n",
      "  (4, 42916)\t0.09257415163048713\n",
      "  (4, 21558)\t0.07383545885299136\n",
      "  (4, 56448)\t0.09322680222405186\n",
      "  (4, 45627)\t0.07389465383222822\n",
      "  (4, 44953)\t0.0962139770904883\n",
      "  (4, 53419)\t0.04176926344354861\n",
      "  (4, 40332)\t0.08617719650560408\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Создание экземпляра TfidfVectorizer с настройками по умолчанию\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Преобразование текста в TF-IDF признаки (разреженное представление)\n",
    "tfidf_features_sparse = tfidf_vectorizer.fit_transform(df['text'])\n",
    "\n",
    "print(tfidf_features_sparse[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e71c9b18-39f0-4ba5-a8c2-710e3f49cba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.2-cp39-cp39-win_amd64.whl (24.0 MB)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\fatik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\fatik\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-7.0.4-py3-none-any.whl (61 kB)\n",
      "Collecting wrapt\n",
      "  Downloading wrapt-1.16.0-cp39-cp39-win_amd64.whl (37 kB)\n",
      "Installing collected packages: wrapt, smart-open, gensim\n",
      "Successfully installed gensim-4.3.2 smart-open-7.0.4 wrapt-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\users\\fatik\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e88d57da-e466-4c8d-819e-a7a7c569c08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность вектора для слова 'movie': 100\n",
      "Вектор для слова 'movie': [ 0.02543544  0.09133368 -0.20022058 -0.16027072  0.34290126 -0.07865588\n",
      " -0.09535958  1.0606991   0.36915353 -0.7411711  -0.32558337  0.01466207\n",
      " -0.35498226  0.14602064  0.21817449  0.23576611 -0.05780831 -0.38597688\n",
      " -0.39864442 -0.08124109  0.00385325  0.01333416  0.7073492  -0.05555516\n",
      "  0.42208543  0.2896786   0.387052    0.46134505  0.07780652 -0.21555382\n",
      "  0.35050488  0.2525598   0.17673467 -0.4805886  -0.05347675  0.12342978\n",
      "  0.41139823  0.10380424  0.08029428  0.14270468  0.3038241   0.11715885\n",
      " -0.44592515  0.17657289  0.23369579 -0.1643479   0.01804748 -0.01374978\n",
      " -0.19041163  0.67200005  0.20353362 -0.72210467  0.21120161  0.1465426\n",
      " -0.05041103  0.3382066  -0.05182466  0.14792472 -0.3251863   0.48630995\n",
      " -0.06677806 -0.32883242  0.03415896  0.3277397   0.43970737  0.41750622\n",
      "  0.0336133   0.1620965  -0.06517904  0.20871492 -0.02769133  0.32750466\n",
      "  0.49568012 -0.07504764  0.17832513  0.26645464  0.54155827  0.26707712\n",
      "  0.20547415  0.0838316  -0.1922931  -0.22638017  0.5645227  -0.15754053\n",
      " -0.08797053 -0.09440515 -0.24375848 -0.28406817  0.06783826 -0.12784676\n",
      "  0.22776327 -0.13560869 -0.14858419  0.01358663 -0.03918587  0.10359485\n",
      "  0.18141988 -0.1427789  -0.27552232 -0.12643035]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df['tokenized_text'] = df['text'].apply(word_tokenize)\n",
    "\n",
    "# Построение модели FastText\n",
    "fasttext_model = FastText(sentences=df['tokenized_text'], vector_size=100, window=5, min_count=1, workers=4, sg=1)\n",
    "\n",
    "word_vectors = fasttext_model.wv\n",
    "\n",
    "word_vector_example = word_vectors['movie']\n",
    "\n",
    "print(\"Размерность вектора для слова 'movie':\", len(word_vector_example))\n",
    "\n",
    "# Вывод вектора для слова 'movie'\n",
    "print(\"Вектор для слова 'movie':\", word_vector_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e298c945-b994-4daf-9190-969544093a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1746)\t0.20722062778845346\n",
      "  (0, 31118)\t0.15712591618796062\n",
      "  (0, 55705)\t0.18612640927110397\n",
      "  (0, 5314)\t0.258299513651735\n",
      "  (0, 59526)\t0.0831446277683261\n",
      "  (0, 22523)\t0.1408573656572451\n",
      "  (0, 56860)\t0.2506513811693412\n",
      "  (0, 61122)\t0.24189648946665898\n",
      "  (0, 6669)\t0.09687413061654844\n",
      "  (0, 31135)\t0.21157554771084985\n",
      "  (0, 67008)\t0.1261630624856939\n",
      "  (0, 13108)\t0.265638683841361\n",
      "  (0, 11033)\t0.22073894184142087\n",
      "  (0, 34911)\t0.1982771316123151\n",
      "  (0, 66654)\t0.20270383235435555\n",
      "  (0, 8595)\t0.16880742601704532\n",
      "  (0, 35459)\t0.0536267180002675\n",
      "  (0, 1552)\t0.07942517578319769\n",
      "  (0, 45907)\t0.2361373776863723\n",
      "  (0, 47408)\t0.16892248295729584\n",
      "  (0, 53419)\t0.06358858788954391\n",
      "  (0, 20165)\t0.09589612390715939\n",
      "  (0, 4858)\t0.11731638952383695\n",
      "  (0, 55697)\t0.37516159963322737\n",
      "  (0, 40332)\t0.13119422710139952\n",
      "  :\t:\n",
      "  (4, 5927)\t0.09625120188321254\n",
      "  (4, 2824)\t0.07174939509243015\n",
      "  (4, 12368)\t0.11354261300520527\n",
      "  (4, 4079)\t0.1502408824289187\n",
      "  (4, 49087)\t0.10787816159981137\n",
      "  (4, 66110)\t0.08816500952379949\n",
      "  (4, 49083)\t0.0870746405118177\n",
      "  (4, 25765)\t0.03956374622009596\n",
      "  (4, 60922)\t0.07651158664194273\n",
      "  (4, 56175)\t0.05618456654510985\n",
      "  (4, 22729)\t0.0478895083288865\n",
      "  (4, 22612)\t0.056785035103182675\n",
      "  (4, 25068)\t0.0425274461167564\n",
      "  (4, 41319)\t0.10619837601628175\n",
      "  (4, 49093)\t0.0442701817160292\n",
      "  (4, 22079)\t0.0973703446548808\n",
      "  (4, 33541)\t0.06656294977391562\n",
      "  (4, 47347)\t0.0666535334216833\n",
      "  (4, 42916)\t0.09257415163048713\n",
      "  (4, 21558)\t0.07383545885299136\n",
      "  (4, 56448)\t0.09322680222405186\n",
      "  (4, 45627)\t0.07389465383222822\n",
      "  (4, 44953)\t0.0962139770904883\n",
      "  (4, 53419)\t0.04176926344354861\n",
      "  (4, 40332)\t0.08617719650560408\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_features_sparse = tfidf_vectorizer.fit_transform(df['text'])\n",
    "\n",
    "print(tfidf_features_sparse[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ce9a06d1-207e-469e-89d4-dda4271dd39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность вектора для слова 'movie': 100\n",
      "Вектор для слова 'movie': [-0.9335438   2.2902682   0.2591475   0.784158    1.6816498  -1.7226582\n",
      "  1.0018433   0.7240882  -2.326664   -0.849651    1.7452344  -0.28731814\n",
      "  0.3800731  -0.7220229   0.39817387  1.627208    1.7779096   0.7604499\n",
      "  0.11994741 -0.59861314  0.25681046  1.3784455   1.1365837   0.08954363\n",
      " -0.96222425  0.3988171   0.567734    2.8996217  -0.10686078 -1.9476078\n",
      "  1.601706   -1.1181844   1.6357892   2.557266   -1.1870253   1.3911401\n",
      "  1.6809916   1.7725483   1.0171402   1.7586166   0.27921543  0.49749514\n",
      "  1.1115919  -1.8347789  -0.7415821  -0.9961971   1.1280138  -1.7586695\n",
      " -0.24256924 -0.72063136 -0.19094998  0.31948066  0.97196096 -0.85125965\n",
      "  1.6689363  -0.0425076   1.452454    2.9714115   1.6072172   0.42529652\n",
      " -1.7253176  -0.6355784   2.090407   -0.20244205 -1.9575484  -0.8652287\n",
      "  1.1287776  -0.68572444 -1.2192538   0.48137838 -0.15801647  0.5563314\n",
      "  0.5585543   1.6327436   1.0599624  -1.4546244  -1.8092867  -0.4629908\n",
      " -1.327274   -0.4826909  -0.5661331  -2.2074897   2.678457    2.8423755\n",
      "  0.33067858  0.5314472  -0.61706156 -0.40363464  1.3988824  -0.20110463\n",
      " -2.0590236   1.2092804   2.5623686   1.1497915   1.5187982  -0.10418459\n",
      " -0.4760469   0.5263156   1.8405231   1.730277  ]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Построение модели Word2Vec\n",
    "word2vec_model = Word2Vec(sentences=df['tokenized_text'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "word_vectors = word2vec_model.wv\n",
    "\n",
    "word_vector_example = word_vectors['movie']\n",
    "\n",
    "print(\"Размерность вектора для слова 'movie':\", len(word_vector_example))\n",
    "\n",
    "print(\"Вектор для слова 'movie':\", word_vector_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dc2f3a40-7fa3-4fa0-ae18-16a01f657c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наиболее похожие тексты на текст с индексом 0\n",
      "1. Индекс текста: 18776, Сходство: 0.2273800398824537\n",
      "2. Индекс текста: 2978, Сходство: 0.22698655591514683\n",
      "3. Индекс текста: 11069, Сходство: 0.20206700850807724\n",
      "4. Индекс текста: 2674, Сходство: 0.18094912312319805\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "cosine_similarities = cosine_similarity(tfidf_features_sparse, tfidf_features_sparse)\n",
    "\n",
    "query_index = 0\n",
    "similar_texts_indices = cosine_similarities[query_index].argsort()[:-6:-1]  # Получаем индексы наиболее похожих текстов\n",
    "\n",
    "# Вывод наиболее похожих текстов и их сходство\n",
    "print(\"Наиболее похожие тексты на текст с индексом\", query_index)\n",
    "for i, idx in enumerate(similar_texts_indices[1:], start=1):  # Не учитываем сам текст (idx 0)\n",
    "    similarity = cosine_similarities[query_index][idx]\n",
    "    print(f\"{i}. Индекс текста: {idx}, Сходство: {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "95572198-99a3-48c3-b88c-12f2187b35b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Индекс текста: 16178, Сходство: 0.7503987550735474\n",
      "2. Индекс текста: 1381, Сходство: 0.7241132259368896\n",
      "3. Индекс текста: 5268, Сходство: 0.7167215347290039\n",
      "4. Индекс текста: 4214, Сходство: 0.7052783966064453\n",
      "5. Индекс текста: 333, Сходство: 0.6984853744506836\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# Вычисление вектора запроса \n",
    "query = \"Fun TV show catchy title song wrinklies getting things done outrageous but brilliant entertainment learning experience mystery drama comedy forensic work reminiscent of Quincy, ME and Barney Miller screw ups but job gets done\"\n",
    "query_words = [word for word in query.split() if word in word_vectors.key_to_index]\n",
    "query_vectors = [word_vectors.get_vector(word) for word in query_words]\n",
    "query_vector = np.mean(query_vectors, axis=0).reshape(1, -1)\n",
    "\n",
    "# Вычисление косинусного сходства между запросом и каждым текстом\n",
    "similarities = cosine_similarity(query_vector, word_vectors.vectors)\n",
    "\n",
    "# Получение индексов наиболее похожих текстов\n",
    "similar_texts_indices = similarities.argsort()[0][::-1]\n",
    "\n",
    "# Вывод наиболее похожих текстов\n",
    "for i, idx in enumerate(similar_texts_indices[:5], start=1):\n",
    "    print(f\"{i}. Индекс текста: {idx}, Сходство: {similarities[0][idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "90e5c94a-29cf-4716-941c-6b449293b78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Индекс текста: 16178, Сходство: 0.7468650341033936\n",
      "2. Индекс текста: 1381, Сходство: 0.7269189357757568\n",
      "3. Индекс текста: 5268, Сходство: 0.7118467092514038\n",
      "4. Индекс текста: 4214, Сходство: 0.7075476050376892\n",
      "5. Индекс текста: 2746, Сходство: 0.6971070766448975\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Вычисление вектора запроса\n",
    "query = \"Fun TV show catchy title song wrinklies getting things done outrageous but brilliant entertainment learning experience mystery drama comedy forensic work reminiscent of Quincy, ME and Barney Miller screw ups but job gets done\"\n",
    "query_vector = np.mean([word_vectors[word] for word in word_tokenize(query) if word in word_vectors], axis=0).reshape(1, -1)\n",
    "\n",
    "similarities = cosine_similarity(query_vector, word_vectors.vectors)\n",
    "\n",
    "similar_texts_indices = similarities.argsort()[0][::-1]\n",
    "\n",
    "for i, idx in enumerate(similar_texts_indices[:5], start=1):\n",
    "    print(f\"{i}. Индекс текста: {idx}, Сходство: {similarities[0][idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e285d4a8-47b7-497c-bff9-b6576c2d860d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.16666666666666666\n",
      "Recall: 1.0\n",
      "F1-score: 0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "true_index = 1381\n",
    "best_search_indices = [1381, 16178, 5268, 2746, 4214, 333]\n",
    "\n",
    "true_results = [1 if index == true_index else 0 for index in best_search_indices]\n",
    "predicted_results = [1] * len(best_search_indices)\n",
    "\n",
    "precision = precision_score(true_results, predicted_results)\n",
    "recall = recall_score(true_results, predicted_results)\n",
    "f1 = f1_score(true_results, predicted_results)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
